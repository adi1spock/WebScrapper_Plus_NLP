{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import get_variable_name\n",
    "import selenium\n",
    "import sys\n",
    "from selenium.webdriver.common.by import By\n",
    "PATH=\"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "from selenium import webdriver\n",
    "# setting webdriver option to initially convert all the pages to english\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--lang=es')\n",
    "driver = webdriver.Chrome(executable_path=PATH, chrome_options=options)\n",
    "\n",
    "sys.setrecursionlimit(15000)\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making list for checking if the text has matching string\n",
    "ner1=[\"member\",\"members\",\"minister\",\"ministers\",\"ministries\",\"directory\",\"directories\",\"council\",\"a-z\",\"government a-z\",\n",
    "     \"parliament\",\"federal government\",\"cabinet members\",\"cabinet\",\"board member\",\"board members\",\"contact directory\",\n",
    "     \"government leader\",\"government leaders\",\"senator\",\"senators\",\"representative\",\"representatives\",\"legislator\",\n",
    "     \"legislators\",\"governor\",\"mayor\",\"state authorities\",\"adminstrator\",\"adminstrative\",\"senators'\",\"department\",\n",
    "     \"chancellery\",\"ministry\",\"member's\",\"mla\",\"mlas\",\"mlcs\",\"mla\",\"mlc\",\"lt. governor\",\"governors\",\"lt. governors\",\n",
    "     \"state\",\"states\",\"unions\",\"agriculture\",\"telecommunication\",\"defence\",\"armed\",\"medical\",\"hospitality\",\"tourism\",\n",
    "     \"education\",\"husbandry\",\"security\",\"development\",\"urban\",\"environment\",\"housing\",\"rural\",\"art\",\"commerce\",\n",
    "     \"finance\",\"tax\",\"power\",\"transport\",\"labour\",\"sports\",\"youth\",\"health\",\"family\",\"law\",\"infrastructure\",\"science\",\n",
    "     \"rural\",\"communication\",\"communications\",\"who\",\"contact\",\"municipal\",\"website of\"]\n",
    "ner=[]\n",
    "\n",
    "# generating synonyms using nltk wordnet library\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "for i in ner1:\n",
    "    for syn in wordnet.synsets(i):\n",
    "        for lemma in syn.lemmas():\n",
    "            ner.append(lemma.name())\n",
    "name_finder=[\"hon\",\"honourable\",\"mr\",\"mrs\",\"ms\",\"shri\",\"sri\",\"smt.\",\"dr\",\"dr.\",\"msc\",\"mba\",\"mag.\"\n",
    "             \"sushri\",\"his highness\",\"his excellency\",\"lieutenant\",\"her excellency\",\"lord\",\"sh.\"]\n",
    "\n",
    "role_=[\"mp\",\"mla\",\"prime minister\",\"minister of\",\"commisioner\",\"chairperson\",\"president\",\"vice\",\"hon'ble\"]\n",
    "\n",
    "ministry=[\"ministry of\",\"department of\"]\n",
    "#creating different list of variables\n",
    "name=[]\n",
    "role=[]\n",
    "position=[]\n",
    "\n",
    "\n",
    "allowed_domains=[\"https://www.india.gov.in/my-government\",\"https://uaecabinet.ae/en\",\n",
    "     \"https://www.gov.za/\",\"https://www.usa.gov/\",\"https://www.australia.gov.au/\",\"https://www.gov.uk/\",\n",
    "     \"https://www.gov.si/\",\"https://www.canada.ca/en.html\",\"https://www.government.se/\",\n",
    "     \"https://www.bundeskanzleramt.gv.at/en.html\",\"https://www.gov.si/en/\",\"https://www.govt.nz/\",\n",
    "     \"https://denmark.dk/\",\n",
    "     \"https://www.admin.ch/gov/en/start.html\",\"https://www.regjeringen.no/en/id4/\"]\n",
    "\n",
    "java=[\"javascript\",\"javascript:;\",\"javascript:void(0);\"]\n",
    "print(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kamikaze=[\"member\",\"members\",\"minister\",\"ministers\",\"ministries\",\"directory\",\"directories\",\"council\",\"a-z\",\"government a-z\",\n",
    "          \"parliament\",\"federal government\",\"cabinet members\",\"cabinet\",\"board member\",\"board members\",\"contact directory\",\n",
    "          \"government leader\",\"government leaders\",\"senator\",\"senators\",\"representative\",\"representatives\",\"legislator\",\n",
    "          \"legislators\",\"governor\",\"mayor\",\"state authorities\",\"adminstrator\",\"adminstrative\",\"senators'\",\n",
    "          \"mla\",\"mlas\",\"mlcs\",\"mla\",\"mlc\",\"lt. governor\",\"governors\",\"lt. governors\",\"who\",\"contact\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"\n",
    "          \"8\",\"9\",\"municipal\",\"website of\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country(x):\n",
    "    if(x==\"https://www.india.gov.in/my-government\"):\n",
    "        country=\"india\"\n",
    "    elif(x==\"https://uaecabinet.ae/en\"):\n",
    "        country=\"uae\"\n",
    "    elif(x==\"https://www.gov.za/\"):\n",
    "        country=\"south-africa\"\n",
    "    elif(x==\"https://www.usa.gov/\"):\n",
    "        country=\"usa\"\n",
    "    elif(x==\"https://www.australia.gov.au/\"):\n",
    "        country=\"australia\"\n",
    "    elif(x==\"https://www.gov.uk/\"):\n",
    "        country=\"uk\"\n",
    "    elif(x==\"https://www.gov.si/\"):\n",
    "        country=\"slovenia\"\n",
    "    elif(x==\"https://www.canada.ca/en.html\"):\n",
    "        country=\"canada\"\n",
    "    elif(x==\"https://www.government.se/\"):\n",
    "        country=\"sweden\"\n",
    "    elif(x==\"https://www.bundeskanzleramt.gv.at/en.html\"):\n",
    "        country=\"austria\"\n",
    "    elif(x==\"https://www.gov.si/en/\"):\n",
    "        country=\"singapore\"\n",
    "    elif(x==\"https://www.govt.nz/\"):\n",
    "        country=\"new zeland\"\n",
    "    elif(x==\"https://denmark.dk/\"):\n",
    "        country=\"denmark\"\n",
    "    elif(x==\"https://www.admin.ch/gov/en/start.html\"):\n",
    "        country=\"switzerland\"\n",
    "    elif(x==\"https://www.regjeringen.no/en/id4/\"):\n",
    "        country=\"norway\"\n",
    "        \n",
    "        \n",
    "def extractor(x):\n",
    "    x=x.lower()\n",
    "    for i in name_finder:\n",
    "        if(bool(re.search(i,x))==True):\n",
    "            name.append(x)\n",
    "    for i in ministry:\n",
    "        if(bool(re.search(i,x))==True):\n",
    "            role.append(x)\n",
    "    for i in role_:\n",
    "        if(bool(re.search(i,x))==True):\n",
    "            position.append(x)\n",
    "            \n",
    "            \n",
    "def lowering_f(x):\n",
    "    x=x.lower()\n",
    "    return x\n",
    "\n",
    "def checker(x):\n",
    "    for i in ner:\n",
    "        if(re.search(i,x.lower())):\n",
    "            return True\n",
    "        \n",
    "def name_checker(x):\n",
    "    for i in name_finder:\n",
    "        if(bool(re.search(i,x.lower()))):\n",
    "            return True\n",
    "        \n",
    "new_list=[]\n",
    "def element_remover(list_name,index):\n",
    "    for i in range(len(list_name)):\n",
    "        if i!=index:\n",
    "            new_list.append(list_name[i])\n",
    "    list_name=list(new_list)\n",
    "    list_name=list_name[:]\n",
    "    new_list.clear()\n",
    "    return list_name\n",
    "\n",
    "def as_c(x):\n",
    "    for i in java:\n",
    "        if(re.search(i,x.lower())):\n",
    "            return True\n",
    "            \n",
    "#recursion last link end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHALLENGE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "b=[]\n",
    "global cnt \n",
    "global cnt2\n",
    "global cnt3\n",
    "global country\n",
    "cnt=0\n",
    "cnt2=0\n",
    "cnt3=0\n",
    "country_name=\"\"\n",
    "country_list=[]\n",
    "def scrape(x):\n",
    "    global cnt \n",
    "    global cnt2\n",
    "    global cnt3\n",
    "    global country\n",
    "    driver.get(x)\n",
    "    elems=driver.find_elements_by_tag_name('a')\n",
    "    for elem in elems:\n",
    "        href = elem.get_attribute('href')\n",
    "        if href is not None:\n",
    "            a.append(href)\n",
    "        text=elem.get_attribute('text')\n",
    "        if text is not None:\n",
    "            b.append(text)\n",
    "    #checking if text enclosed in a tag has anything in common with ner file\n",
    "    new_list1=[]   \n",
    "    count=0\n",
    "    a1=list(a)\n",
    "    a1=a[:]\n",
    "    b1=list(b)\n",
    "    b1=b[:]\n",
    "    b.clear()\n",
    "    a.clear()\n",
    "    for i in b1:\n",
    "        if(checker(i)):\n",
    "            b.append(i)\n",
    "            a.append(a1[count])\n",
    "        count+=1\n",
    "    #javascript false href fremover\n",
    "    count1=0\n",
    "    a2=list(a)\n",
    "    a2=a[:]\n",
    "    b2=list(b)\n",
    "    b2=b[:]\n",
    "    b.clear()\n",
    "    a.clear()\n",
    "    for i in a2:\n",
    "        if(as_c(i)):\n",
    "            count1=count1\n",
    "        else:\n",
    "            a.append(i)\n",
    "            b.append(b2[count1])\n",
    "        count1+=1\n",
    "        \n",
    "    # duplicate remover\n",
    "    dup_a=list(a)\n",
    "    dup_a=a[:]\n",
    "    dup_b=list(b)\n",
    "    dup_b=b[:]\n",
    "    a.clear()\n",
    "    b.clear()\n",
    "    count_x=0\n",
    "    for i in dup_a:\n",
    "        if i not in a:\n",
    "            a.append(i)\n",
    "            b.append(dup_b[count_x])\n",
    "            if(count_x>cnt2):\n",
    "                country_list.append(country_name)\n",
    "        count_x+=1\n",
    "    print(len(b))\n",
    "    cnt=cnt+1\n",
    "    \n",
    "    #level deciding\n",
    "    if(cnt==cnt2):\n",
    "        cnt2=len(a)\n",
    "        cnt3+=1\n",
    "    if(cnt3==15):\n",
    "        return 0\n",
    "    \n",
    "    scrape(a[cnt])\n",
    "    \n",
    "\n",
    "for al in allowed_domains:\n",
    "    country_name=country(al)\n",
    "    driver.get(al)\n",
    "    elems=driver.find_elements_by_tag_name('a')\n",
    "    for elem in elems:\n",
    "        href = elem.get_attribute('href')\n",
    "        if href is not None:\n",
    "            a.append(href)\n",
    "        text=elem.get_attribute('text')\n",
    "        if text is not None:\n",
    "            b.append(text)\n",
    "        \n",
    "\n",
    "    #ner checker\n",
    "    count=0\n",
    "    a1=list(a)\n",
    "    a1=a[:]\n",
    "    b1=list(b)\n",
    "    b1=b[:]\n",
    "    b.clear()\n",
    "    a.clear()\n",
    "    for i in b1:\n",
    "        if(checker(i)):\n",
    "            b.append(i)\n",
    "            a.append(a1[count])\n",
    "        count+=1\n",
    "    #javascript href remover\n",
    "    count1=0\n",
    "    a2=list(a)\n",
    "    a2=a[:]\n",
    "    b2=list(b)\n",
    "    b2=b[:]\n",
    "    b.clear()\n",
    "    a.clear()\n",
    "    for i in a2:\n",
    "        if(as_c(i)):\n",
    "            count1=count1\n",
    "        else:\n",
    "            a.append(i)\n",
    "            b.append(b2[count1])\n",
    "            if(count1>cnt2):\n",
    "                country_list.append(country_name)\n",
    "        count1+=1\n",
    "\n",
    "    print(b)\n",
    "\n",
    "    cnt=cnt+1\n",
    "    cnt2=len(a)\n",
    "    scrape(a[cnt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now extracting even more probable places where we can found names\n",
    "print(len(b))\n",
    "extractor_a=[]\n",
    "extractor_b=[]\n",
    "b_tempz=[]\n",
    "a_tempz=[]\n",
    "a_tempz=list(a)\n",
    "a_tempz=a[:]\n",
    "b_tempz=list(b)\n",
    "b_tempz=b[:]\n",
    "a.clear()\n",
    "b.clear()\n",
    "country_list1=[]\n",
    "for i in range(len(b_tempz)):\n",
    "    for j in range(len(kamikaze)):\n",
    "        if(re.search(kamikaze[j],b_tempz[i].lower())):\n",
    "            b.append(b_tempz[i])\n",
    "            a.append(a_tempz[i])\n",
    "            continue\n",
    "            \n",
    "#removing those text elemnts whose charachter length is more than 35\n",
    "a_tempz=list(a)\n",
    "a_tempz=a[:]\n",
    "b_tempz=list(b)\n",
    "b_tempz=b[:]\n",
    "a.clear()\n",
    "b.clear()\n",
    "for i in range(len(b_tempz)):\n",
    "    if(len(b_tempz[i])<=35):\n",
    "        b.append(b_tempz[i])\n",
    "        a.append(a_tempz[i])\n",
    "        country_list1.append(country_list[i])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_field=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHALLENGE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting li elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "PATH=\"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "from selenium import webdriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--lang=es')\n",
    "driver = webdriver.Chrome(executable_path=PATH, chrome_options=options)\n",
    "tag=[\"a\",\"img\",\"button\",\"video\",\"link\",\"form\",\"label\",\"input\"]\n",
    "text=[]\n",
    "global count_1\n",
    "count_1=0\n",
    "\n",
    "for ix in a:\n",
    "    \n",
    "    driver.get(ix)\n",
    "    html_source = driver.page_source\n",
    "\n",
    "    #print(html_source)\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    print(len(soup.find_all(\"li\")))\n",
    "    txt=soup.find_all(\"li\")\n",
    "    for j in range(len(txt)):\n",
    "        count=0\n",
    "        for i in tag:\n",
    "            if bool(txt[j].find_all(i)):\n",
    "                count=1\n",
    "                continue\n",
    "        if count==0:\n",
    "            text.append(txt[j].string)\n",
    "            country_field.append(country_list1[count_1])\n",
    "    count_1+=1\n",
    "for i in text:\n",
    "    field.append(i)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting table elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "PATH=\"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "from selenium import webdriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--lang=es')\n",
    "driver = webdriver.Chrome(executable_path=PATH, chrome_options=options)\n",
    "field2=[]\n",
    "count_1=0\n",
    "#getting all the columns of a ow individually\n",
    "for ix in a:\n",
    "    driver.get(ix)\n",
    "    html_source = driver.page_source\n",
    "    td=[]\n",
    "    tr=[]\n",
    "    #print(html_source)\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    table=soup.find_all(\"table\")\n",
    "    for i in range(len(table)):\n",
    "        tr=table[i].find_all(\"tr\")\n",
    "    for i in range(len(tr)):\n",
    "        td=td+tr[i].find_all(\"td\")\n",
    "        length=len(tr[i].find_all(\"td\"))\n",
    "    for i in td:\n",
    "        i=str(i)\n",
    "        i=i[4:]\n",
    "        i=i[:-5]\n",
    "        field2.append(i)\n",
    "        country_field.append(country_list1[count_1])\n",
    "    count_1+=1\n",
    "\n",
    "#now connecting all the columns to make one row\n",
    "new_field=[]\n",
    "for i in field2:\n",
    "    data=\"\"\n",
    "    #print(len(field))\n",
    "    if(len(field2)>0):\n",
    "        for i in range(length):\n",
    "            data=data+field2[i]+\" \"\n",
    "        new_field.append(data)\n",
    "        field2=field2[length:]\n",
    "        data=\" \"\n",
    "\n",
    "for i in field2:\n",
    "    field.append(i)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting text-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "PATH=\"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "from selenium import webdriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--lang=es')\n",
    "driver = webdriver.Chrome(executable_path=PATH, chrome_options=options)\n",
    "field1=[]\n",
    "count_1=0\n",
    "for ix in a:\n",
    "    \n",
    "    \n",
    "    driver.get(ix)\n",
    "    html_source = driver.page_source\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "\n",
    "\n",
    "    div=soup.find_all(\"div\")\n",
    "    count=0\n",
    "    field=[]\n",
    "    for i in range(len(div)):\n",
    "        data=\"\"\n",
    "\n",
    "        if(div[i].find_all(\"img\")):\n",
    "\n",
    "            img_div=div[i].find_all(\"img\")\n",
    "            if(div[i+1].find_all(\"p\")):\n",
    "                for x in range(len(div[i+1].find_all(\"p\"))):\n",
    "                    x1=div[i+1].find_all(\"p\")\n",
    "                    data=data+str(x1[x].string)+\" \"\n",
    "                    if(div[i+2].find_all(\"p\")):\n",
    "                        for x_1 in range(len(div[i+2].find_all(\"p\"))):\n",
    "                            x4=div[i+2].find_all(\"p\")\n",
    "                            data=data+str(x4[x_1].string)+\" \"\n",
    "\n",
    "            elif(div[i+1].find_all([\"h1\", \"h2\", \"h3\", \"h4\" ,\"h5\", \"h6\"])):\n",
    "                for x in range(len(div[i+1].find_all([\"h1\", \"h2\", \"h3\", \"h4\" ,\"h5\", \"h6\"]))):\n",
    "                    x2=div[i+1].find_all([\"h1\", \"h2\", \"h3\", \"h4\" ,\"h5\", \"h6\"])\n",
    "                    data=data+str(x2[x].string)+\" \"\n",
    "                    if(div[i+2].find_all(\"p\")):\n",
    "                        for x_2 in range(len(div[i+2].find_all(\"p\"))):\n",
    "                            x5=div[i+2].find_all(\"p\")\n",
    "                            data=data+str(x5[x_2].string)+\" \"\n",
    "\n",
    "            elif(div[i+1].find_all([\"h1\", \"h2\", \"h3\", \"h4\" ,\"h5\", \"h6\"])):\n",
    "                for x in range(len(div[i+1].find_all([\"h1\", \"h2\", \"h3\", \"h4\" ,\"h5\", \"h6\"]))):\n",
    "                    x3=div[i+1].find_all([\"h1\", \"h2\", \"h3\", \"h4\" ,\"h5\", \"h6\"])\n",
    "                    data=data+str(x3[x].string)+\" \"\n",
    "                    if(div[i+2].find_all([\"h1\", \"h2\", \"h3\", \"h4\" ,\"h5\", \"h6\"])):\n",
    "                        for x_3 in range(len(div[i+2].find_all([\"h1\", \"h2\", \"h3\", \"h4\" ,\"h5\", \"h6\"]))):\n",
    "                            x6=div[i+2].find_all([\"h1\", \"h2\", \"h3\", \"h4\" ,\"h5\", \"h6\"])\n",
    "                            data=data+str(x6[x_3].string)+\" \"\n",
    "\n",
    "            elif(div[i+1].find_all(\"span\")):\n",
    "                for x in range(len(div[i+1].find_all(\"span\"))):\n",
    "                    x7=div[i+1].find_all(\"span\")\n",
    "                    data=data+str(x7[x].string)+\" \"\n",
    "                    if(div[i+2].find_all(\"li\")):\n",
    "                        for x_8 in range(len(div[i+2].find_all(\"li\"))):\n",
    "                            x9=div[i+2].find_all(\"li\")\n",
    "                            data=data+str(x9[x_8].string)+\" \"\n",
    "\n",
    "\n",
    "            field1.append(data)\n",
    "            country_field.append(country_list1[count_1])\n",
    "    count_1+=1\n",
    "\n",
    "        \n",
    "#removing field element having charachter length more than 500\n",
    "new_field=[]\n",
    "for i in field:\n",
    "    if(len(i)<500):\n",
    "        new_field.append(i)\n",
    "for i in new_field:\n",
    "    field.append(i)\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if any word is related to living beings for removing wrong data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "a=[]\n",
    "index=[]\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def living(x):\n",
    "    j2=word_tokenize(x)\n",
    "    for j1 in j2:\n",
    "        for i in range(len(wordnet.synsets(j1))):\n",
    "            syn=wordnet.synsets(j1)[i]\n",
    "            a.append(syn.hypernym_paths())\n",
    "        print(a)\n",
    "        for i in a:\n",
    "            for j in i:\n",
    "                for k in j:\n",
    "                    k=str(k)\n",
    "                    if(k==\"Synset('living_thing.n.01')\"):\n",
    "                        a.clear()\n",
    "                        return 1\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "count=0\n",
    "for i in field:\n",
    "    x=living(i)\n",
    "    print(x)\n",
    "    if(x==1):\n",
    "        co=0\n",
    "    else:\n",
    "        print(\"k\")\n",
    "        index.append(count)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fianl filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=list(field)\n",
    "temp=field[:]\n",
    "temp1=list(country_field)\n",
    "temp1=country_field[:]\n",
    "for x in range(len(field)):\n",
    "    for y in index:\n",
    "        if(x!=y):\n",
    "            field.append(temp[x])\n",
    "            country_field.append(temp1[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting job\n",
    "a=[]\n",
    "job=[]\n",
    "data=\"\"\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def job_name(x1):    \n",
    "    a.clear()\n",
    "    j2=word_tokenize(x1)\n",
    "    for j1 in j2:\n",
    "        data=\"\"\n",
    "        for x in range(len(wordnet.synsets(j1))):\n",
    "            syn=wordnet.synsets(j1)[x]\n",
    "            a.append(syn.hypernym_paths())\n",
    "            for i in a:\n",
    "                for j in i:\n",
    "                    for k in j:\n",
    "                        print(k)\n",
    "                        k=str(k)\n",
    "                        if(k==\"Synset('abstraction.n.06')\"):\n",
    "                            data+=j1\n",
    "                            print(j1)\n",
    "                            count=1\n",
    "                            return j1\n",
    "                        elif(k==\"Synset('causal_agent.n.01')\"):\n",
    "                            data+=j1\n",
    "                            print(j1)\n",
    "                            count=1\n",
    "                            return j1\n",
    "                        elif(k==\"Synset('person.n.01')\"):\n",
    "                            data+=j1\n",
    "                            print(j1)\n",
    "                            return j1\n",
    "                            count=1\n",
    "                if(count==1):\n",
    "                    break\n",
    "\n",
    "            if(count==1):\n",
    "                break\n",
    "            \n",
    "        \n",
    "for g in field:\n",
    "    job.append(job_name(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHALLENGE 3 (partially complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(len(country)==len(field)):\n",
    "    pd.DataFrame({'description': field, 'country': country_field, 'job': job}).to_csv('data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
