{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for checking living being"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('causal_agent.n.01'), Synset('person.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('person.n.01')]], [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('natural_object.n.01'), Synset('body.n.01'), Synset('human_body.n.01'), Synset('person.n.02')]], [[Synset('entity.n.01'), Synset('abstraction.n.06'), Synset('group.n.01'), Synset('collection.n.01'), Synset('class.n.01'), Synset('grammatical_category.n.01'), Synset('person.n.03')]]]\n",
      "1\n",
      "[[[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('causal_agent.n.01'), Synset('person.n.01'), Synset('adult.n.01'), Synset('professional.n.01'), Synset('health_professional.n.01'), Synset('medical_practitioner.n.01'), Synset('doctor.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('person.n.01'), Synset('adult.n.01'), Synset('professional.n.01'), Synset('health_professional.n.01'), Synset('medical_practitioner.n.01'), Synset('doctor.n.01')]], [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('causal_agent.n.01'), Synset('person.n.01'), Synset('intellectual.n.01'), Synset('scholar.n.01'), Synset('theologian.n.01'), Synset('doctor_of_the_church.n.01')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('person.n.01'), Synset('intellectual.n.01'), Synset('scholar.n.01'), Synset('theologian.n.01'), Synset('doctor_of_the_church.n.01')]], [[Synset('entity.n.01'), Synset('abstraction.n.06'), Synset('psychological_feature.n.01'), Synset('event.n.01'), Synset('act.n.02'), Synset('activity.n.01'), Synset('diversion.n.01'), Synset('play.n.08'), Synset('doctor.n.03')]], [[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('causal_agent.n.01'), Synset('person.n.01'), Synset('intellectual.n.01'), Synset('scholar.n.01'), Synset('doctor.n.04')], [Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('person.n.01'), Synset('intellectual.n.01'), Synset('scholar.n.01'), Synset('doctor.n.04')]], [[Synset('change.v.02'), Synset('modify.v.01'), Synset('corrupt.v.04'), Synset('load.v.05'), Synset('sophisticate.v.03')]], [[Synset('treat.v.03'), Synset('doctor.v.02')]], [[Synset('change.v.01'), Synset('better.v.02'), Synset('repair.v.01')]]]\n",
      "1\n",
      "[]\n",
      "[]\n",
      "None\n",
      "k\n",
      "[]\n",
      "[]\n",
      "None\n",
      "k\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "a=[]\n",
    "field=[\"person is alive\",\"doctor is playing\",\"dnjnj djnfjenf\",\"sjcdjne jnfenfejn\"]\n",
    "index=[]\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def living(x):\n",
    "    j2=word_tokenize(x)\n",
    "    for j1 in j2:\n",
    "        for i in range(len(wordnet.synsets(j1))):\n",
    "            syn=wordnet.synsets(j1)[i]\n",
    "            a.append(syn.hypernym_paths())\n",
    "        print(a)\n",
    "        for i in a:\n",
    "            for j in i:\n",
    "                for k in j:\n",
    "                    k=str(k)\n",
    "                    if(k==\"Synset('living_thing.n.01')\"):\n",
    "                        a.clear()\n",
    "                        return 1\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "count=0\n",
    "for i in field:\n",
    "    x=living(i)\n",
    "    print(x)\n",
    "    if(x==1):\n",
    "        co=0\n",
    "    else:\n",
    "        print(\"k\")\n",
    "        index.append(count)\n",
    "    count+=1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for opening webdriver english option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: use options instead of chrome_options\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "import sys\n",
    "from selenium.webdriver.common.by import By\n",
    "PATH=\"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "from selenium import webdriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--lang=es')\n",
    "driver = webdriver.Chrome(executable_path=PATH, chrome_options=options)\n",
    "driver.get(\"https://www.bundeskanzleramt.gv.at/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aditya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('entity.n.01')\n",
      "Synset('physical_entity.n.01')\n",
      "Synset('causal_agent.n.01')\n",
      "doctor\n",
      "Synset('entity.n.01')\n",
      "Synset('physical_entity.n.01')\n",
      "Synset('causal_agent.n.01')\n",
      "engineer\n"
     ]
    }
   ],
   "source": [
    "#extracting job\n",
    "a=[]\n",
    "job=[]\n",
    "data=\"\"\n",
    "field=[\"doctor is mad\",\"ggjjk jkkg kkkf\",\"engineer person\"]\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def job_name(x1):    \n",
    "    a.clear()\n",
    "    j2=word_tokenize(x1)\n",
    "    for j1 in j2:\n",
    "        data=\"\"\n",
    "        for x in range(len(wordnet.synsets(j1))):\n",
    "            syn=wordnet.synsets(j1)[x]\n",
    "            a.append(syn.hypernym_paths())\n",
    "            for i in a:\n",
    "                for j in i:\n",
    "                    for k in j:\n",
    "                        print(k)\n",
    "                        k=str(k)\n",
    "                        if(k==\"Synset('abstraction.n.06')\"):\n",
    "                            data+=j1\n",
    "                            print(j1)\n",
    "                            count=1\n",
    "                            return j1\n",
    "                        elif(k==\"Synset('causal_agent.n.01')\"):\n",
    "                            data+=j1\n",
    "                            print(j1)\n",
    "                            count=1\n",
    "                            return j1\n",
    "                        elif(k==\"Synset('person.n.01')\"):\n",
    "                            data+=j1\n",
    "                            print(j1)\n",
    "                            return j1\n",
    "                            count=1\n",
    "                if(count==1):\n",
    "                    break\n",
    "\n",
    "            if(count==1):\n",
    "                break\n",
    "            \n",
    "        \n",
    "for g in field:\n",
    "    job.append(job_name(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doctor', None, 'engineer']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
